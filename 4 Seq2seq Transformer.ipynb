{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fra-eng.zip\n",
      "  inflating: _about.txt              \n",
      "  inflating: fra.txt                 \n"
     ]
    }
   ],
   "source": [
    "# see http://www.manythings.org/anki\n",
    "\n",
    "! wget http://www.manythings.org/anki/fra-eng.zip\n",
    "    \n",
    "! unzip fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "with open('fra.txt', 'r') as fr:\n",
    "    \n",
    "    nmt_data = []\n",
    "    \n",
    "    for lines in fr.readlines():\n",
    "        splits = lines.split('\\t')\n",
    "        \n",
    "        i = {\n",
    "            'src': splits[1],\n",
    "            'tgt': splits[0]\n",
    "        }\n",
    "        \n",
    "        nmt_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = 'nmt_vocab'\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    \n",
    "    os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Save vocab_file\n",
    "\n",
    "with open(os.path.join(folder, 'src_vocab.txt'), 'w') as src:\n",
    "    el = ' '.join([a['src'] for a in nmt_data])\n",
    "    src.write(el)\n",
    "\n",
    "with open(os.path.join(folder, 'tgt_vocab.txt'), 'w') as tgt:\n",
    "    el = ' '.join([a['tgt'] for a in nmt_data])\n",
    "    tgt.write(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': \"J'ai payé en espèce.\", 'tgt': 'I paid in cash.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmt_data[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import Lowercase, NFD, StripAccents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(vocab_file, vocab_size=30000, single_format='[SOS] $A [EOS]'):\n",
    "    \n",
    "    # Instanciate a trainer\n",
    "    trainer = tokenizers.trainers.WordLevelTrainer(vocab_size=vocab_size, special_tokens=['[PAD]', '[SOS]', '[EOS]', '[UNK]'])\n",
    "    \n",
    "    # Instanciate a tokenizer\n",
    "    tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "    \n",
    "    # Adding pre-tokenizer\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    \n",
    "    # Adding normalizers\n",
    "    tokenizer.normalizer = normalizers.Sequence([Lowercase(), NFD(), StripAccents()])\n",
    "    \n",
    "    # Post-Processing\n",
    "    tokenizer.post_processor = TemplateProcessing(\n",
    "        single=single_format,\n",
    "        special_tokens=[\n",
    "            (\"[SOS]\", 1), \n",
    "            (\"[EOS]\", 2)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    tokenizer.train([vocab_file], trainer)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "src_tokenizer = create_tokenizer(os.path.join(folder, 'src_vocab.txt'), single_format='$A')\n",
    "\n",
    "tgt_tokenizer = create_tokenizer(os.path.join(folder, 'tgt_vocab.txt'), single_format='[SOS] $A [EOS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def switch_mode(tokenizer, max_len=50):\n",
    "    tokenizer.enable_truncation(max_len)\n",
    "    tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'paid', 'in', 'cash', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenizer.encode(nmt_data[10000]['tgt']).tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class NMTdata(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        d = self.data[idx]\n",
    "        \n",
    "        # return source and target\n",
    "        return d['src'], d['tgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    # collate for batch tokenization\n",
    "    \n",
    "    src = [item[0] for item in batch]\n",
    "    tgt = [item[1] for item in batch]\n",
    "    \n",
    "    switch_mode(src_tokenizer)\n",
    "    switch_mode(tgt_tokenizer)\n",
    "    \n",
    "    src = src_tokenizer.encode_batch(src)\n",
    "    src = torch.LongTensor([i.ids for i in src])\n",
    "    \n",
    "    tgt = tgt_tokenizer.encode_batch(tgt)\n",
    "    tgt = torch.LongTensor([i.ids for i in tgt])\n",
    "                \n",
    "    return [src, tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185583\n"
     ]
    }
   ],
   "source": [
    "all_dataset = NMTdata(nmt_data)\n",
    "\n",
    "print(len(all_dataset))\n",
    "\n",
    "train, val = random_split(all_dataset, [len(all_dataset)-5000, 5000])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=128, shuffle=True, collate_fn=collate, num_workers=15)\n",
    "\n",
    "val_loader = DataLoader(val, batch_size=512, shuffle=False, collate_fn=collate, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### import modules\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_utils import PositionEmbedding, get_masks, TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class NMTmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model=512, n_head=8, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        \n",
    "        # dropout for regularization\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        \n",
    "        # embedding for source sequences\n",
    "        self.scr_embedding = nn.Embedding(src_vocab, d_model, padding_idx=0)\n",
    "        \n",
    "        # embedding for target sequences\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab, d_model, padding_idx=0)\n",
    "        \n",
    "        # positional embedding\n",
    "        self.pos_embedding = PositionEmbedding(200, d_model)\n",
    "        \n",
    "        # transformer encoder\n",
    "        self.encoder = TransformerEncoder(d_model, n_head, num_layers)\n",
    "        \n",
    "        # transformer decoder\n",
    "        self.decoder = TransformerDecoder(d_model, n_head, num_layers)\n",
    "        \n",
    "        # fully connected network\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(d_model, tgt_vocab)\n",
    "        )\n",
    "        \n",
    "    def encode(self, src):\n",
    "        \n",
    "        # src: sourse sequence of shape: [batch_size, src_len]\n",
    "        \n",
    "        src_mask, _ = get_masks(src)\n",
    "        \n",
    "        src_emb = self.scr_embedding(src)\n",
    "        \n",
    "        src_emb = self.pos_embedding(src_emb)\n",
    "        \n",
    "        src_emb = self.drop(src_emb)\n",
    "        \n",
    "        memory = self.encoder(src_emb, src_mask)\n",
    "        \n",
    "        return memory  # [batch_size, src_len, d_model]\n",
    "    \n",
    "    def decode(self, tgt, memory):\n",
    "        \n",
    "        # tgt: decoder input for teacher forcing [batch_size, tgt_len]\n",
    "        # memory: encode output [batch_size, src_len, d_model]\n",
    "        \n",
    "        tgt_mask, causal = get_masks(tgt)\n",
    "        \n",
    "        tgt_mask = tgt_mask * causal # combine causal and padding mask\n",
    "        \n",
    "        tgt_emb = self.tgt_embedding(tgt)\n",
    "        \n",
    "        tgt_emb = self.pos_embedding(tgt_emb)\n",
    "        \n",
    "        tgt_emb = self.drop(tgt_emb)\n",
    "        \n",
    "        out = self.decoder(y=tgt_emb, memory=memory, y_mask=tgt_mask)\n",
    "        \n",
    "        return self.fc(out) # [batch_size, tgt_len, tgt_vocab_size]\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \n",
    "        memory = self.encode(src) # encode src\n",
    "        \n",
    "        out = self.decode(tgt, memory) # decoding with teacher forcing\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    \n",
    "    def compute_loss(self, x, y):\n",
    "        \n",
    "        pred = self.forward(x, y[:, :-1]) # sos, ...\n",
    "        \n",
    "        y = y[:, 1:] # ...eos\n",
    "        \n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        pred = pred.view(-1, self.tgt_vocab)\n",
    "        \n",
    "        loss = F.cross_entropy(pred, y, ignore_index=0)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([0.3050, 0.9295, 0.8356, 0.8977])\n",
      "training mode:\n",
      " tensor([0.0000, 0.0000, 1.6712, 0.0000])\n",
      "eval mode:\n",
      " tensor([0.3050, 0.9295, 0.8356, 0.8977])\n"
     ]
    }
   ],
   "source": [
    "# # Dropout regularization\n",
    "\n",
    "class Dropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.training:\n",
    "            \n",
    "            mask = torch.bernoulli(torch.empty_like(x).uniform_(0, 1))\n",
    "            \n",
    "            x = (1/self.p) * x * mask\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return x\n",
    "        \n",
    "x = torch.rand(4,)\n",
    "\n",
    "drop = Dropout()\n",
    "\n",
    "print('x:\\n', x)\n",
    "\n",
    "print('training mode:\\n', drop(x))\n",
    "\n",
    "drop.eval()\n",
    "\n",
    "print('eval mode:\\n', drop(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    drop = nn.Dropout(p=0.5)\n",
    "    \n",
    "    x = drop(x)\n",
    "    \n",
    "    for layer in self.transformer_layers:\n",
    "        if np.random.rand() > 0.5:\n",
    "            x = layer(x)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(net: nn.Module, opt: torch.optim, dataloader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    pbar = tqdm(dataloader)\n",
    "    \n",
    "    for x, y in pbar:\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        loss = net.compute_loss(x, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        \n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        losses.append(loss_item)\n",
    "        \n",
    "        pbar.set_description(f'train_loss = {np.array(losses).mean()}')\n",
    "        \n",
    "    return np.array(losses).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(net: nn.Module, dataloader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "     \n",
    "    losses = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        loss = net.compute_loss(x, y)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "                    \n",
    "    return np.array(losses).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# model = NMTmodel(src_vocab=src_tokenizer.get_vocab_size(), tgt_vocab=tgt_tokenizer.get_vocab_size(), d_model=512, n_head=8, num_layers=2).cuda()\n",
    "\n",
    "# opt = torch.optim.AdamW(model.parameters(), lr=1e-4) # original paper use warmup step + decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.659289836883545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 3.122909759647199: 100%|██████████| 1411/1411 [01:52<00:00, 12.52it/s] \n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1426881313323975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 1.9407147846688284: 100%|██████████| 1411/1411 [03:40<00:00,  6.39it/s]\n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5852023363113403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 1.529400000328886: 100%|██████████| 1411/1411 [04:00<00:00,  5.86it/s] \n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3283339142799377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 1.287834175548851: 100%|██████████| 1411/1411 [05:58<00:00,  3.94it/s] \n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.175497567653656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 1.1204880964325135: 100%|██████████| 1411/1411 [05:45<00:00,  4.08it/s]\n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0687022507190704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 0.9963250955649929: 100%|██████████| 1411/1411 [03:42<00:00,  6.34it/s]\n",
      "  0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926928997039794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_loss = 0.8961147483488416: 100%|██████████| 1411/1411 [07:20<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9388803243637085\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    if i==0:\n",
    "        print(validate(model, val_loader))\n",
    "        \n",
    "    train_one_epoch(model, opt, train_loader)\n",
    "    \n",
    "    print(validate(model, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 30 min of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "model.eval()\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def topk_sampling(logits, k):\n",
    "    \n",
    "    logits = logits.squeeze()\n",
    "    \n",
    "    topk = torch.topk(logits, k)\n",
    "    \n",
    "    probs, indices = torch.softmax(topk.values, dim=0).numpy(), topk.indices.numpy()   \n",
    "    \n",
    "    return np.random.choice(indices, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def translate(french):\n",
    "    \n",
    "    src = torch.LongTensor(src_tokenizer.encode(french).ids).unsqueeze(0)\n",
    "        \n",
    "    y = torch.LongTensor([[1]]) # sos\n",
    "    \n",
    "    memory = model.encode(src)\n",
    "    \n",
    "    sequences = [1]\n",
    "    \n",
    "    while True:\n",
    "                \n",
    "        pred = model.decode(y, memory).squeeze(0)[-1]\n",
    "                        \n",
    "        pred = topk_sampling(pred, 3) # torch.argmax(pred, -1).item()\n",
    "        \n",
    "        if pred == 2: # eos \n",
    "            break\n",
    "        \n",
    "        sequences.append(pred)\n",
    "        \n",
    "        y = torch.LongTensor([sequences])\n",
    "        \n",
    "    return tgt_tokenizer.decode(sequences[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: Tu ferais mieux de prendre conseil auprès d'un médecin.\n",
      "target: You'd better ask the doctor for advice.\n",
      "pred: you ' d better take some advice of a doctor ' s advice .\n"
     ]
    }
   ],
   "source": [
    "example = nmt_data[val.indices[np.random.randint(0, 5000)]]\n",
    "\n",
    "print('source:', example['src'])\n",
    "\n",
    "print('target:', example['tgt'])\n",
    "\n",
    "pred = translate(example['src'])\n",
    "\n",
    "print('pred:', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam search decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from allennlp.nn.beam_search import BeamSearch, TopPSampler, TopKSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Sample images from validation set\n",
    "\n",
    "test_src = iter(val_loader).__next__()[0]\n",
    "\n",
    "# Take 16\n",
    "test_src = test_src[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 20,  23,   5,  11,  45,  29, 426,   4,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create a batch of <sos> tokens\n",
    "\n",
    "sos_tokens = torch.ones((test_src.size()[0], 1)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Encode the sequences\n",
    "\n",
    "with torch.no_grad():\n",
    "    memory = model.encode(test_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Instanciate beam search\n",
    "\n",
    "bs = BeamSearch(end_index=2, beam_size=10, max_steps=20, sampler=TopPSampler(p=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# the code is ugly but it works ...\n",
    "\n",
    "def next_step(last_pred, states):\n",
    "    \n",
    "    # unsqueeze the second dimension\n",
    "    if len(last_pred.size()) == 1:\n",
    "        last_pred = last_pred.unsqueeze(1)\n",
    "        \n",
    "    # extract    \n",
    "    memory = states['memory']\n",
    "        \n",
    "    y = states['sequences']\n",
    "    \n",
    "    y = torch.cat([y, last_pred], dim=1)\n",
    "                \n",
    "    # prediction for last token\n",
    "    pred = model.decode(y, memory)[:, -1, :]\n",
    "            \n",
    "    states['sequences'] =  y\n",
    "            \n",
    "    return F.log_softmax(pred, dim=-1), states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "states = {'memory': memory, 'sequences': torch.LongTensor([])}\n",
    "\n",
    "out_beam, log_probs = bs.search(sos_tokens, states, next_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, 64)\n",
    "\n",
    "print('source:', src_tokenizer.decode(test_src[idx].numpy()))\n",
    "\n",
    "print('prediction:')\n",
    "\n",
    "for s, p in zip(out_beam[idx], log_probs[idx]):\n",
    "    \n",
    "    print(f' - {tgt_tokenizer.decode(s.numpy())} ==> prob = {torch.exp(p).item(): 0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_emb = model.tgt_embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5883, -0.0920,  0.0062,  ..., -0.4923, -1.2821,  0.7908],\n",
       "        [ 0.5635,  0.9206, -0.4681,  ..., -2.3200,  0.0091,  1.5956],\n",
       "        ...,\n",
       "        [-1.2475,  0.2879,  1.7130,  ...,  0.7948,  0.4980,  1.3692],\n",
       "        [ 0.0163, -0.0325,  0.2305,  ..., -0.7854,  1.9704, -0.4423],\n",
       "        [-0.1573, -0.9495, -0.3234,  ...,  1.0498, -0.6279,  0.5638]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tgt_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict(sorted(vocab.items(), key=lambda x: x[1]))\n",
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_emb(word):\n",
    "    \n",
    "    idx = word2id[word]\n",
    "    \n",
    "    return fr_emb[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([-0.1581, -0.1551, -0.1487,  ...,  0.1705,  0.1904,  1.0000]),\n",
       "indices=tensor([4697, 9216,  314,  ..., 7115, 2923,  144]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.cosine_similarity(get_word_emb('love').view(1, -1), fr_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fasting'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[7115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_UZA",
   "language": "python",
   "name": "py37_uza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
